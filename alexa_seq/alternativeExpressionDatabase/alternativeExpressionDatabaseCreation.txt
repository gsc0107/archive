
#Create a series of example databases for various species 
#Species to try:

#Human - ENSEMBL = homo_sapiens_core_55_37  UCSC = hg19
#Mouse - ENSEMBL = mus_musculus_core_54_37g  UCSC = mm9
#Rat - ENSEMBL = rattus_norvegicus_core_54_34v  UCSC = rn4
#Chimp - ENSEMBL = pan_troglodytes_core_54_21k  UCSC = panTro2
#Drosophila - ENSEMBL = drosophila_melanogaster_core_54_54b  UCSC = dm3 (not sure if this matches EnsEMBL...)
#Yeast - ENSEMBL = saccharomyces_cerevisiae_core_54_1i  UCSC = sacCer1
#Chicken ENSEMBL = gallus_gallus_core_54_2l  UCSC = galGal3

#Install EnsEMBL API version 54: (see EnsEMBL website for details)
/home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/installEnsemblAPI.pl  --install_dir=/home/malachig/svn/alexa_seq/ensembl_api/  --ensembl_version=54

#Install EnsEMBL database if you have not already done so.  Directions are provided here:
http://ensembl.org/info/docs/webcode/install/ensembl-data.html


####################################################################################################
#0.) Set up an ALEXA database for the desired version of the EnsEMBL database
# - See ALEXA user manual for details

#Log into a mysql server (with a user that can create databases) and perform the following commands
mysql
DROP DATABASE ALEXA_hs_55_37;
CREATE DATABASE ALEXA_hs_55_37; 
USE ALEXA_hs_55_37;
SOURCE ~/svn/solexa_analysis/sql/ALEXA_schema.sql;

DROP DATABASE ALEXA_mm_54_37g;
CREATE DATABASE ALEXA_mm_54_37g; 
USE ALEXA_mm_54_37g;
SOURCE ~/svn/solexa_analysis/sql/ALEXA_schema.sql;

DROP DATABASE ALEXA_rn_54_34v;
CREATE DATABASE ALEXA_rn_54_34v; 
USE ALEXA_rn_54_34v;
SOURCE ~/svn/solexa_analysis/sql/ALEXA_schema.sql;

DROP DATABASE ALEXA_pt_54_21k;
CREATE DATABASE ALEXA_pt_54_21k; 
USE ALEXA_pt_54_21k;
SOURCE ~/svn/solexa_analysis/sql/ALEXA_schema.sql;

DROP DATABASE ALEXA_dm_54_54b;
CREATE DATABASE ALEXA_dm_54_54b; 
USE ALEXA_dm_54_54b;
SOURCE ~/svn/solexa_analysis/sql/ALEXA_schema.sql;

DROP DATABASE ALEXA_sc_54_1i;
CREATE DATABASE ALEXA_sc_54_1i; 
USE ALEXA_sc_54_1i;
SOURCE ~/svn/solexa_analysis/sql/ALEXA_schema.sql;

DROP DATABASE ALEXA_gg_54_2l;
CREATE DATABASE ALEXA_gg_54_2l; 
USE ALEXA_gg_54_2l;
SOURCE ~/svn/solexa_analysis/sql/ALEXA_schema.sql;


#Install EnsEMBL database: homo_sapiens_core_53_36o (see EnsEMBL website for details)

####################################################################################################
#1.) Make target directories
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  mkdir /projects/malachig/sequence_databases/$DB/
  cd /projects/malachig/sequence_databases/$DB/
  mkdir alexa_db
  mkdir genes genes/temp 
  mkdir exonBoundaries exonBoundaries/temp exonBoundaries/blastdb
  mkdir exonJunctions exonJunctions/temp exonJunctions/blastdb
  mkdir exonRegions exonRegions/temp exonRegions/blastdb/ exonRegions/blastdb/temp 
  mkdir intergenics intergenics/temp intergenics/blastdb
  mkdir introns introns/temp introns/blastdb
  mkdir transcripts transcripts/blastdb 
  mkdir logs logs/createExonRegionDatabase logs/createExonJunctionDatabase logs/createExonBoundaryDatabase logs/annotateExonJunctions logs/annotateExonBoundaries logs/createIntronDatabase logs/createIntergenicDatabase
  mkdir mrna_est mrna_est/partitions 
  mkdir jobs jobs/temp
  mkdir repeats
  mkdir repeats/blastdb
done


#2-A.) Get repeat elements for each species
# http://www.girinst.org/repbase/update/browse.php
# Select RepeatClass 'All'.  Taxon '$species'.  And chose the '$species and Ancestral' download option
# Download data in both fasta and EMBL format
#Store in the following dir

/projects/malachig/sequence_databases/$DB/repeats/
cd /projects/malachig/sequence_databases/$DB/repeats/
perl -ne '$_ =~ s/\t/\|/g; print "$_"' repeats.fa > blastdb/repeats.fa
mv repeats.fa repeats.txt
cd blastdb/
/home/pubseq/BioSw/BLAST2/blast2.2.18_x64/bin/formatdb -i repeats.fa -t repeats -p F -o F -n repeats
gzip repeats.fa

function processRepeatFiles() {
  cd /projects/malachig/sequence_databases/$1/repeats/
  perl -ne '$_ =~ s/\t/\|/g; print "$_"' repeats.fa > blastdb/repeats.fa
  mv repeats.fa repeats.txt
  cd blastdb/
  /home/pubseq/BioSw/BLAST2/blast2.2.18_x64/bin/formatdb -i repeats -t repeats -p F -o F -n repeats
  gzip repeats.fa
}

processRepeatFiles dm_54_54b DrosophilaMelanogaster
processRepeatFiles gg_54_2l GallusGallus
processRepeatFiles hs_55_37 HomoSapiens
processRepeatFiles mm_54_37g MusMusculus
processRepeatFiles pt_54_21k PanTroglodytes
processRepeatFiles rn_54_34v RattusNorvegicus
processRepeatFiles sc_54_1i SaccharomycesCerevisiae


####################################################################################################
#2-B.) Get mRNA/EST alignment tables from UCSC
cd /projects/malachig/sequence_databases/hs_55_37/mrna_est/
ftp hgdownload.cse.ucsc.edu
prompt
cd /goldenPath/hg19/database/
mget all_mrna.txt.gz all_est.txt.gz xenoMrna.txt.gz xenoEst.txt.gz gbCdnaInfo.txt.gz
exit

cd /projects/malachig/sequence_databases/mm_54_37g/mrna_est/
ftp hgdownload.cse.ucsc.edu
prompt
cd /goldenPath/mm9/database/
mget all_mrna.txt.gz all_est.txt.gz xenoMrna.txt.gz xenoEst.txt.gz gbCdnaInfo.txt.gz
exit

cd /projects/malachig/sequence_databases/rn_54_34v/mrna_est/
ftp hgdownload.cse.ucsc.edu
prompt
cd /goldenPath/rn4/database/
mget all_mrna.txt.gz all_est.txt.gz xenoMrna.txt.gz xenoEst.txt.gz gbCdnaInfo.txt.gz
exit

cd /projects/malachig/sequence_databases/pt_54_21k/mrna_est/
ftp hgdownload.cse.ucsc.edu
prompt
cd /goldenPath/panTro2/database/
mget all_mrna.txt.gz all_est.txt.gz xenoMrna.txt.gz xenoEst.txt.gz gbCdnaInfo.txt.gz
exit

cd /projects/malachig/sequence_databases/dm_54_54b/mrna_est/
ftp hgdownload.cse.ucsc.edu
prompt
cd /goldenPath/dm3/database/
mget all_mrna.txt.gz all_est.txt.gz xenoMrna.txt.gz xenoEst.txt.gz gbCdnaInfo.txt.gz
exit

cd /projects/malachig/sequence_databases/sc_54_1i/mrna_est/
ftp hgdownload.cse.ucsc.edu
prompt
cd /goldenPath/sacCer1/database/
mget all_mrna.txt.gz all_est.txt.gz xenoMrna.txt.gz xenoEst.txt.gz gbCdnaInfo.txt.gz
exit

cd /projects/malachig/sequence_databases/gg_54_2l/mrna_est/
ftp hgdownload.cse.ucsc.edu
prompt
cd /goldenPath/galGal3/database/
mget all_mrna.txt.gz all_est.txt.gz xenoMrna.txt.gz xenoEst.txt.gz gbCdnaInfo.txt.gz
exit

#2-C.) Create a database of genbank-to-species mappings
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createGenBankIdToSpeciesDatabase.pl  --ucsc_align_dir=/projects/malachig/sequence_databases/$DB/mrna_est/   --out_dir=/projects/malachig/sequence_databases/$DB/mrna_est/
done

#2-D.) Partition the UCSC alignment files by chromosome
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/partitionUcscAlignmentFiles.pl  --ucsc_align_dir=/projects/malachig/sequence_databases/$DB/mrna_est/   --out_dir=/projects/malachig/sequence_databases/$DB/mrna_est/partitions/
done


#2-E.) Get Entrez gene annotations for this species
#e.g. for human:
cd /projects/malachig/sequence_databases/hs_53_36o/
wget ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz
gunzip Homo_sapiens.gene_info.gz

####################################################################################################
#3.) Populate the ALEXA database:
/home/malachig/svn/solexa_analysis/getEnsemblGeneData.pl  --ensembl_api_version=55  --species=Human  --ensembl_database=homo_sapiens_core_55_37  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_hs_55_37  --alexa_server=jango.bcgsc.ca  --alexa_user=malachig  --alexa_password=gEEnom$  --all_ids=1  --populate_database=yes  --logfile=/projects/malachig/sequence_databases/hs_55_37/logs/getEnsemblGeneData_LOG.txt

/home/malachig/svn/solexa_analysis/getEnsemblGeneData.pl  --ensembl_api_version=54  --species=Mouse  --ensembl_database=mus_musculus_core_54_37g  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_mm_54_37g  --alexa_server=jango.bcgsc.ca  --alexa_user=malachig  --alexa_password=gEEnom$  --all_ids=1  --populate_database=yes  --logfile=/projects/malachig/sequence_databases/mm_54_37g/logs/getEnsemblGeneData_LOG.txt

/home/malachig/svn/solexa_analysis/getEnsemblGeneData.pl  --ensembl_api_version=54  --species=Rat  --ensembl_database=rattus_norvegicus_core_54_34v  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_rn_54_34v  --alexa_server=jango.bcgsc.ca  --alexa_user=malachig  --alexa_password=gEEnom$  --all_ids=1  --populate_database=yes  --logfile=/projects/malachig/sequence_databases/rn_54_34v/logs/getEnsemblGeneData_LOG.txt

/home/malachig/svn/solexa_analysis/getEnsemblGeneData.pl  --ensembl_api_version=54  --species=Chimp  --ensembl_database=pan_troglodytes_core_54_21k  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_pt_54_21k  --alexa_server=jango.bcgsc.ca  --alexa_user=malachig  --alexa_password=gEEnom$  --all_ids=1  --populate_database=yes  --logfile=/projects/malachig/sequence_databases/pt_54_21k/logs/getEnsemblGeneData_LOG.txt

/home/malachig/svn/solexa_analysis/getEnsemblGeneData.pl  --ensembl_api_version=54  --species="Drosophila melanogaster"  --ensembl_database=drosophila_melanogaster_core_54_54b  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_dm_54_54b  --alexa_server=jango.bcgsc.ca  --alexa_user=malachig  --alexa_password=gEEnom$  --all_ids=1  --populate_database=yes  --logfile=/projects/malachig/sequence_databases/dm_54_54b/logs/getEnsemblGeneData_LOG.txt

/home/malachig/svn/solexa_analysis/getEnsemblGeneData.pl  --ensembl_api_version=54  --species="saccharomyces cerevisiae"  --ensembl_database=saccharomyces_cerevisiae_core_54_1i  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_sc_54_1i  --alexa_server=jango.bcgsc.ca  --alexa_user=malachig  --alexa_password=gEEnom$  --all_ids=1  --populate_database=yes  --logfile=/projects/malachig/sequence_databases/sc_54_1i/logs/getEnsemblGeneData_LOG.txt

/home/malachig/svn/solexa_analysis/getEnsemblGeneData.pl  --ensembl_api_version=54  --species=Chicken  --ensembl_database=gallus_gallus_core_54_2l  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_gg_54_2l  --alexa_server=jango.bcgsc.ca  --alexa_user=malachig  --alexa_password=gEEnom$  --all_ids=1  --populate_database=yes  --logfile=/projects/malachig/sequence_databases/gg_54_2l/logs/getEnsemblGeneData_LOG.txt



####################################################################################################
#4.) Get a list of chromosome names for this EnsEMBL build, also use a script to partition the genome into smaller pieces to facilitate parallel processing on a cluster
echo 'SELECT DISTINCT chromosome from Gene;' | mysql -N ALEXA_hs_55_37 > /projects/malachig/sequence_databases/hs_55_37/ChromosomeNames.txt
echo 'SELECT DISTINCT chromosome from Gene;' | mysql -N ALEXA_mm_54_37g > /projects/malachig/sequence_databases/mm_54_37g/ChromosomeNames.txt
echo 'SELECT DISTINCT chromosome from Gene;' | mysql -N ALEXA_rn_54_34v > /projects/malachig/sequence_databases/rn_54_34v/ChromosomeNames.txt
echo 'SELECT DISTINCT chromosome from Gene;' | mysql -N ALEXA_pt_54_21k > /projects/malachig/sequence_databases/pt_54_21k/ChromosomeNames.txt
echo 'SELECT DISTINCT chromosome from Gene;' | mysql -N ALEXA_dm_54_54b > /projects/malachig/sequence_databases/dm_54_54b/ChromosomeNames.txt
echo 'SELECT DISTINCT chromosome from Gene;' | mysql -N ALEXA_sc_54_1i > /projects/malachig/sequence_databases/sc_54_1i/ChromosomeNames.txt
echo 'SELECT DISTINCT chromosome from Gene;' | mysql -N ALEXA_gg_54_2l > /projects/malachig/sequence_databases/gg_54_2l/ChromosomeNames.txt

#Get a list of UCSC chromosome names as well
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/
  ls mrna_est/partitions/ | perl -ne 'chomp($_); if ($_ =~ /(chr.*)\_(est|mrna|xest|xmrna).txt.gz/){print "$1\n"}' | sort | uniq > ChromosomeNames_UCSC.txt
done

#*** Compare UCSC and EnsEMBL Chromosome names for each species - compensate for difference somehow  ***
#*** Possibly by adding chromosome name re-maps to ALEXA_DB.pm ***

#*** Also for human it may be wise to eliminate haplotype chromsomes from the analysis 
#Information on these for the latest human build are here: http://www.ncbi.nlm.nih.gov/projects/genome/assembly/grc/human/index.shtml
#To eliminate these, add filter to getEnsemblGeneData.pl so that they are never imported


####################################################################################################
#5-A.) Create jobs to break genomes into manageable pieces (blocks of say 250 genes - without causing breaks within genes)
#250 gene blocks
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=55  --species=Human  --ensembl_database=homo_sapiens_core_55_37  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_hs_55_37  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=250  --outfile=/projects/malachig/sequence_databases/hs_55_37/jobs/temp/EnsEMBL_55_Regions_250genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/hs_55_37/ChromosomeNames.txt > /projects/malachig/sequence_databases/hs_55_37/jobs/partitionEnsemblGenome_250.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=Mouse  --ensembl_database=mus_musculus_core_54_37g  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_mm_54_37g  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=250  --outfile=/projects/malachig/sequence_databases/mm_54_37g/jobs/temp/EnsEMBL_54_Regions_250genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/mm_54_37g/ChromosomeNames.txt > /projects/malachig/sequence_databases/mm_54_37g/jobs/partitionEnsemblGenome_250.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=Rat  --ensembl_database=rattus_norvegicus_core_54_34v  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_rn_54_34v  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=250  --outfile=/projects/malachig/sequence_databases/rn_54_34v/jobs/temp/EnsEMBL_54_Regions_250genes_$_.txt --chr_filter=$_\n"' /projects/malachig/sequence_databases/rn_54_34v/ChromosomeNames.txt > /projects/malachig/sequence_databases/rn_54_34v/jobs/partitionEnsemblGenome_250.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=Chimp  --ensembl_database=pan_troglodytes_core_54_21k  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_pt_54_21k  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=250  --outfile=/projects/malachig/sequence_databases/pt_54_21k/jobs/temp/EnsEMBL_54_Regions_250genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/pt_54_21k/ChromosomeNames.txt > /projects/malachig/sequence_databases/pt_54_21k/jobs/partitionEnsemblGenome_250.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=\"Drosophila melanogaster\"  --ensembl_database=drosophila_melanogaster_core_54_54b  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_dm_54_54b  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=250  --outfile=/projects/malachig/sequence_databases/dm_54_54b/jobs/temp/EnsEMBL_54_Regions_250genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/dm_54_54b/ChromosomeNames.txt > /projects/malachig/sequence_databases/dm_54_54b/jobs/partitionEnsemblGenome_250.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=\"saccharomyces cerevisiae\"  --ensembl_database=saccharomyces_cerevisiae_core_54_1i  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_sc_54_1i  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=250  --outfile=/projects/malachig/sequence_databases/sc_54_1i/jobs/temp/EnsEMBL_54_Regions_250genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/sc_54_1i/ChromosomeNames.txt > /projects/malachig/sequence_databases/sc_54_1i/jobs/partitionEnsemblGenome_250.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=Chicken  --ensembl_database=gallus_gallus_core_54_2l  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_gg_54_2l  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=250  --outfile=/projects/malachig/sequence_databases/gg_54_2l/jobs/temp/EnsEMBL_54_Regions_250genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/gg_54_2l/ChromosomeNames.txt > /projects/malachig/sequence_databases/gg_54_2l/jobs/partitionEnsemblGenome_250.sh

#50 genes blocks
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=55  --species=Human  --ensembl_database=homo_sapiens_core_55_37  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_hs_55_37  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=50  --outfile=/projects/malachig/sequence_databases/hs_55_37/jobs/temp/EnsEMBL_55_Regions_50genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/hs_55_37/ChromosomeNames.txt > /projects/malachig/sequence_databases/hs_55_37/jobs/partitionEnsemblGenome_50.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=Mouse  --ensembl_database=mus_musculus_core_54_37g  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_mm_54_37g  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=50  --outfile=/projects/malachig/sequence_databases/mm_54_37g/jobs/temp/EnsEMBL_54_Regions_50genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/mm_54_37g/ChromosomeNames.txt > /projects/malachig/sequence_databases/mm_54_37g/jobs/partitionEnsemblGenome_50.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=Rat  --ensembl_database=rattus_norvegicus_core_54_34v  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_rn_54_34v  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=50  --outfile=/projects/malachig/sequence_databases/rn_54_34v/jobs/temp/EnsEMBL_54_Regions_50genes_$_.txt --chr_filter=$_\n"' /projects/malachig/sequence_databases/rn_54_34v/ChromosomeNames.txt > /projects/malachig/sequence_databases/rn_54_34v/jobs/partitionEnsemblGenome_50.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=Chimp  --ensembl_database=pan_troglodytes_core_54_21k  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_pt_54_21k  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=50  --outfile=/projects/malachig/sequence_databases/pt_54_21k/jobs/temp/EnsEMBL_54_Regions_50genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/pt_54_21k/ChromosomeNames.txt > /projects/malachig/sequence_databases/pt_54_21k/jobs/partitionEnsemblGenome_50.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=\"Drosophila melanogaster\"  --ensembl_database=drosophila_melanogaster_core_54_54b  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_dm_54_54b  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=50  --outfile=/projects/malachig/sequence_databases/dm_54_54b/jobs/temp/EnsEMBL_54_Regions_50genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/dm_54_54b/ChromosomeNames.txt > /projects/malachig/sequence_databases/dm_54_54b/jobs/partitionEnsemblGenome_50.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=\"saccharomyces cerevisiae\"  --ensembl_database=saccharomyces_cerevisiae_core_54_1i  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_sc_54_1i  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=50  --outfile=/projects/malachig/sequence_databases/sc_54_1i/jobs/temp/EnsEMBL_54_Regions_50genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/sc_54_1i/ChromosomeNames.txt > /projects/malachig/sequence_databases/sc_54_1i/jobs/partitionEnsemblGenome_50.sh
perl -ne 'chomp($_); print "/home/malachig/svn/solexa_analysis/partitionEnsemblGenome.pl --ensembl_api_version=54  --species=Chicken  --ensembl_database=gallus_gallus_core_54_2l  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_gg_54_2l  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --target_gene_count=50  --outfile=/projects/malachig/sequence_databases/gg_54_2l/jobs/temp/EnsEMBL_54_Regions_50genes_$_.txt  --chr_filter=$_\n"' /projects/malachig/sequence_databases/gg_54_2l/ChromosomeNames.txt > /projects/malachig/sequence_databases/gg_54_2l/jobs/partitionEnsemblGenome_50.sh

#5-B.) Submit this jobs to a cluster
ssh apollo
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/jobs/
  mqsub --file partitionEnsemblGenome_50.sh  --name $DB\_PART --mkdir  --delay 5
done

#5-C.) Check that all jobs completed successfully
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo
  echo $DB
  wc -l /projects/malachig/sequence_databases/$DB/jobs/partitionEnsemblGenome_50.sh
  grep Chromosome /projects/malachig/sequence_databases/$DB/jobs/temp/*_50*.txt | wc -l
done


#5-D.) Concatenate the temp partition files into one file for each species
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/
  grep -h -v Chromosome jobs/temp/*_50* > tmp.txt
  head -q -n 1 jobs/temp/*_50* | sort | uniq | cat - tmp.txt > Regions_50_Genes.txt
  rm -f tmp.txt
done


####################################################################################################
#6.) Create a database file for genes 
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  rm -f /projects/malachig/sequence_databases/$DB/genes/temp/*.txt
  export DB
  perl -ne 'unless($_ =~ /Chromosome/){chomp($_); @line=split("\t", $_);  $db=$ENV{"DB"}; print "/home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createGeneDatabase.pl  --database=ALEXA_$db  --server=jango.bcgsc.ca  --user=viewer  --password=viewer  --chr_filter=\"$line[0]:$line[1]:$line[2]-$line[3]\"  --outdir=/projects/malachig/sequence_databases/$db/genes/temp/\n"}' /projects/malachig/sequence_databases/$DB/Regions_250_Genes.txt > /projects/malachig/sequence_databases/$DB/jobs/createGeneDatabase.sh
  bash /projects/malachig/sequence_databases/$DB/jobs/createGeneDatabase.sh

  cd /projects/malachig/sequence_databases/$DB/genes/
  grep -h -v "Gene_ID" temp/*.txt | sort -n -k 1 > tmp.txt
  head -q -n 1 temp/*.txt | sort | uniq | cat - tmp.txt > genes_annotated.txt
  rm -f tmp.txt
  gzip /projects/malachig/sequence_databases/$DB/genes/genes_annotated.txt
  rm -f temp/*.txt
done

####################################################################################################
#7.) Create a database for Exon Regions

#First create jobs .. 
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  rm -f /projects/malachig/sequence_databases/$DB/exonRegions/temp/*.txt
  rm -f /projects/malachig/sequence_databases/$DB/logs/createExonRegionDatabase/*.txt
  export DB
  perl -ne 'unless($_ =~ /Chromosome/){chomp($_); @line=split("\t", $_); $db=$ENV{"DB"}; print "/home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createExonRegionDatabase.pl  --database=ALEXA_$db  --server=jango.bcgsc.ca  --user=viewer  --password=viewer  --chr_filter=\"$line[0]:$line[1]:$line[2]-$line[3]\"  --ucsc_align_dir=/projects/malachig/sequence_databases/$db/mrna_est/partitions/  --genbank_mapfile=/projects/malachig/sequence_databases/$db/mrna_est/GenBankToOrganism.btree  --wiggle=5  --outfile=/projects/malachig/sequence_databases/$db/exonRegions/temp/exonRegions_annotated_$line[0]_$line[1].txt  --fasta_file=/projects/malachig/sequence_databases/$db/exonRegions/blastdb/temp/exonRegions_$line[0]_$line[1].fa  --logfile=/projects/malachig/sequence_databases/$db/logs/createExonRegionDatabase/createExonRegionDatabase_$line[0]_$line[1]_LOG.txt\n"}' /projects/malachig/sequence_databases/$DB/Regions_250_Genes.txt > /projects/malachig/sequence_databases/$DB/jobs/createExonRegionDatabase.sh
done

#Then submit to cluster
ssh apollo
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo cd /projects/malachig/sequence_databases/$DB/jobs/
  cd /projects/malachig/sequence_databases/$DB/jobs/
  echo mqsub --file createExonRegionDatabase.sh --name $DB\_CERD  --mkdir  --delay 5
  mqsub --file createExonRegionDatabase.sh --name $DB\_CERD  --mkdir  --delay 5
done

#Then check success rate
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo
  echo $DB
  grep -h "SCRIPT COMPLETE" /projects/malachig/sequence_databases/$DB/logs/createExonRegionDatabase/* | wc -l
  grep -v Chromosome /projects/malachig/sequence_databases/$DB/Regions_250_Genes.txt | wc -l
done

#Then join all the individual annotation and fasta files together
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"

for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/exonRegions/
  grep -h -v "Gene_ID" temp/*.txt > tmp.txt
  head -q -n 1 temp/*.txt | sort | uniq | cat - tmp.txt > exonRegions_annotated.txt
  rm -f tmp.txt
  gzip exonRegions_annotated.txt
  rm -f temp/*.txt

  cd blastdb/
  cat temp/exonRegions*.fa > exonRegions.fa
  /home/pubseq/BioSw/BLAST2/blast2.2.18_x64/bin/formatdb -i exonRegions.fa -t exonRegions -p F -o T -n exonRegions
  gzip exonRegions.fa
  rm -f temp/*.fa
done


####################################################################################################
#8.) Create a database of Exon Junctions 

#First extract the junctions
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createExonJunctionDatabase.pl  --database=ALEXA_$DB  --server=jango.bcgsc.ca  --user=viewer  --password=viewer  --target_length=62  --outdir=/projects/malachig/sequence_databases/$DB/exonJunctions/  --logfile=/projects/malachig/sequence_databases/$DB/logs/createExonJunctionDatabase/createExonJunctionDatabase_LOG.txt
done

#Then create jobs annotate them
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/
  rm -f exonJunctions/temp/*.txt
  rm -f logs/annotateExonJunctions/*.txt
  export DB

  perl -ne '$db=$ENV{"DB"}; unless($_ =~ /Chromosome/){chomp($_); @line=split("\t", $_); print "/home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/annotateExonJunctions.pl  --database=ALEXA_$db  --server=jango.bcgsc.ca  --user=viewer  --password=viewer  --chr_filter=\"$line[0]:$line[1]:$line[2]-$line[3]\"  --junction_file=/projects/malachig/sequence_databases/$db/exonJunctions/exonJunctions_62mers.txt  --ucsc_align_dir=/projects/malachig/sequence_databases/$db/mrna_est/partitions/   --genbank_mapfile=/projects/malachig/sequence_databases/$db/mrna_est/GenBankToOrganism.btree  --wiggle=3  --outfile=/projects/malachig/sequence_databases/$db/exonJunctions/temp/exonJunctions_annotated_$line[0]_$line[1].txt  --logfile=/projects/malachig/sequence_databases/$db/logs/annotateExonJunctions/annotateExonJunctions_$line[0]_$line[1]_LOG.txt\n"}' /projects/malachig/sequence_databases/$DB/Regions_250_Genes.txt > /projects/malachig/sequence_databases/$DB/jobs/annotateExonJunctions.sh
done

#Then submit these jobs to the cluster
ssh apollo
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo cd /projects/malachig/sequence_databases/$DB/jobs/
  cd /projects/malachig/sequence_databases/$DB/jobs/
  mqsub --file annotateExonJunctions.sh --name $DB\_AEJ  --mkdir  --delay 1
  echo mqsub --file annotateExonJunctions.sh --name $DB\_AEJ  --mkdir  --delay 1
done

#Then check success rate
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo
  echo $DB
  grep -h "SCRIPT COMPLETE" /projects/malachig/sequence_databases/$DB/logs/annotateExonJunctions/* | wc -l
  grep -v Chromosome /projects/malachig/sequence_databases/$DB/Regions_250_Genes.txt | wc -l
done

#Now join the annotation and fasta files together and create a blast database
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/exonJunctions/
  grep -h -v Junction_ID temp/*.txt | sort -n > tmp.txt
  head -q -n 1 temp/*.txt | sort | uniq | cat - tmp.txt > exonJunctions_62mers_annotated.txt
  rm -f tmp.txt
  gzip exonJunctions_62mers_annotated.txt

  cp exonJunctions_62mers.fa blastdb/
  cd blastdb/
  /home/pubseq/BioSw/BLAST2/blast2.2.18_x64/bin/formatdb -i exonJunctions_62mers.fa -t exonJunctions_62mers -p F -o F -n exonJunctions_62mers
  gzip exonJunctions_62mers.fa
done

#If the above step seems to have worked then clean-up temp files...
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/exonJunctions/
  rm -f exonJunctions_62mers.txt
  rm -f temp/*.txt
  rm -f exonJunctions_62mers.fa
done


####################################################################################################
#9.) Create a database of alternative exon boundaries
#First extract the boundaries
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createExonBoundaryDatabase.pl  --database=ALEXA_$DB  --server=jango.bcgsc.ca  --user=viewer  --password=viewer  --target_length=62  --outdir=/projects/malachig/sequence_databases/$DB/exonBoundaries/  --logfile=/projects/malachig/sequence_databases/$DB/logs/createExonBoundaryDatabase/createExonBoundaryDatabase_LOG.txt
done

#Then create jobs annotate them
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/
  rm -f exonBoundaries/temp/*.txt
  rm -f logs/annotateExonBoundaries/*.txt
  export DB

  perl -ne '$db=$ENV{"DB"}; unless($_ =~ /Chromosome/){chomp($_); @line=split("\t", $_); print "/home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/annotateExonBoundaries.pl  --database=ALEXA_$db  --server=jango.bcgsc.ca  --user=viewer  --password=viewer  --chr_filter=\"$line[0]:$line[1]:$line[2]-$line[3]\"  --target_size=62  --boundary_file=/projects/malachig/sequence_databases/$db/exonBoundaries/exonBoundaries_62mers.txt  --ucsc_align_dir=/projects/malachig/sequence_databases/$db/mrna_est/partitions/  --genbank_mapfile=/projects/malachig/sequence_databases/$db/mrna_est/GenBankToOrganism.btree  --wiggle=3  --outfile=/projects/malachig/sequence_databases/$db/exonBoundaries/temp/exonBoundaries_annotated_$line[0]_$line[1].txt  --logfile=/projects/malachig/sequence_databases/$db/logs/annotateExonBoundaries/annotateExonBoundaries_$line[0]_$line[1]_LOG.txt\n"}' /projects/malachig/sequence_databases/$DB/Regions_250_Genes.txt > /projects/malachig/sequence_databases/$DB/jobs/annotateExonBoundaries.sh
done

#Then submit these jobs to the cluster
ssh apollo
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo cd /projects/malachig/sequence_databases/$DB/jobs/
  cd /projects/malachig/sequence_databases/$DB/jobs/
  mqsub --file annotateExonBoundaries.sh --name $DB\_AEB  --mkdir  --delay 5
  echo mqsub --file annotateExonBoundaries.sh --name $DB\_AEB  --mkdir  --delay 5
done

#Then check success rate
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo
  echo $DB
  grep -h "SCRIPT COMPLETE" /projects/malachig/sequence_databases/$DB/logs/annotateExonBoundaries/* | wc -l
  grep -v Chromosome /projects/malachig/sequence_databases/$DB/Regions_250_Genes.txt | wc -l
done

#Now join the annotation and fasta files together and create a blast database
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/exonBoundaries/
  grep -h -v Boundary_ID temp/*.txt | sort -n > tmp.txt
  head -q -n 1 temp/*.txt | sort | uniq | cat - tmp.txt > exonBoundaries_62mers_annotated.txt
  rm -f tmp.txt
  gzip exonBoundaries_62mers_annotated.txt

  cp exonBoundaries_62mers.fa blastdb/
  cd blastdb/
  /home/pubseq/BioSw/BLAST2/blast2.2.18_x64/bin/formatdb -i exonBoundaries_62mers.fa -t exonBoundaries_62mers -p F -o F -n exonBoundaries_62mers
  gzip exonBoundaries_62mers.fa
done

#If the above step seems to have worked then clean-up temp files...
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/exonBoundaries/
  rm -f exonBoundaries_62mers.txt
  rm -f temp/*.txt
  rm -f exonBoundaries_62mers.fa
done


####################################################################################################
#10.) Create a database of all introns

#First create the jobs

#DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
DBS="gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v"
for DB in $DBS
do
  export DB
  perl -ne '$db=$ENV{"DB"}; chomp ($_); @line =split("\t", $_); unless ($_ =~ /Chromosome/){print "/home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createIntronDatabase.pl  --database=ALEXA_$db  --server=jango.bcgsc.ca  --user=viewer  --password=viewer  --min_size=42  --chr_filter=\"$line[0]:$line[1]:$line[2]-$line[3]\"  --ucsc_align_dir=/projects/malachig/sequence_databases/$db/mrna_est/partitions/  --genbank_mapfile=/projects/malachig/sequence_databases/$db/mrna_est/GenBankToOrganism.btree  --wiggle=5  --outdir=/projects/malachig/sequence_databases/$db/introns/temp/  --logfile=/projects/malachig/sequence_databases/$db/logs/createIntronDatabase/createIntronDatabase_$line[0]_$line[1]_LOG.txt\n"}' /projects/malachig/sequence_databases/$DB/Regions_50_Genes.txt > /projects/malachig/sequence_databases/$DB/jobs/createIntronDatabase.sh

  rm -f /projects/malachig/sequence_databases/$DB/logs/createIntronDatabase/*.txt
  rm -f /projects/malachig/sequence_databases/$DB/introns/temp/*.fa
  rm -f /projects/malachig/sequence_databases/$DB/introns/temp/*.txt
done

#Then submit these jobs to the cluster
ssh apollo
#DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
DBS="gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v"
for DB in $DBS
do
  echo cd /projects/malachig/sequence_databases/$DB/jobs/
  cd /projects/malachig/sequence_databases/$DB/jobs/
  mqsub  --file createIntronDatabase.sh  --name $DB\_CID  --mkdir  --delay 15
  echo mqsub  --file createIntronDatabase.sh --name $DB\_CID  --mkdir  --delay 15
done

#Then check success rate
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo
  echo $DB
  grep -h "SCRIPT COMPLETE" /projects/malachig/sequence_databases/$DB/logs/createIntronDatabase/* | wc -l
  grep -v Chromosome /projects/malachig/sequence_databases/$DB/Regions_250_Genes.txt | wc -l
  grep -v Chromosome /projects/malachig/sequence_databases/$DB/Regions_50_Genes.txt | wc -l
done

#Retrieve jobs that need to be rerun - get list of jobs that completed according to their log files - and then filter the batch file with these
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/
  grep "SCRIPT COMPLETE" logs/createIntronDatabase/* | perl -ne 'if ($_ =~ /(create.*\.txt)/){print "$1\n"}' > logs/tmp.txt
  grep -v -f logs/tmp.txt jobs/createIntronDatabase.sh > jobs/createIntronDatabase_REPAIR.sh
  rm -f logs/tmp.txt
done
 
#Now join the annotation and fasta files together and create a blast database
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/introns/

  grep -h -v "Intron_ID" temp/*introns_annotated.txt > tmp.txt
  head -q -n 1 temp/*_introns_annotated.txt | sort | uniq | cat - tmp.txt > introns_annotated.txt
  gzip introns_annotated.txt

  grep -h -v "Active_Region_ID" temp/*intronRegionsActive.txt > tmp.txt
  head -q -n 1 temp/*_intronRegionsActive.txt | sort| uniq | cat - tmp.txt > activeIntronRegions.txt
  gzip activeIntronRegions.txt

  grep -h -v "Silent_Region_ID" temp/*intronRegionsSilent.txt > tmp.txt
  head -q -n 1 temp/*_intronRegionsSilent.txt | sort | uniq | cat - tmp.txt > silentIntronRegions.txt
  gzip silentIntronRegions.txt

  cat temp/*.fa > blastdb/introns.fa
  cd blastdb/ 
  /home/pubseq/BioSw/BLAST2/blast2.2.18_x64/bin/formatdb -i introns.fa -t introns -p F -o F -n introns
  gzip introns.fa
done

#If the above step seems to have worked then clean-up temp files...




####################################################################################################
#11.) Create a database of all intergenic regions


#First create the jobs
#INFOS="'dm_54_54b-Drosophila_melanogaster-drosophila_melanogaster_core_54_54b' 'gg_54_2l-Chicken-gallus_gallus_core_54_2l' 'hs_55_37-Human-homo_sapiens_core_55_37' 'mm_54_37g-Mouse-mus_musculus_core_54_37g' 'pt_54_21k-Chimp-pan_troglodytes_core_54_21k' 'rn_54_34v-Rat-rattus_norvegicus_core_54_34v' 'sc_54_1i-saccharomyces_cerevisiae-saccharomyces_cerevisiae_core_54_1i'"
INFOS="'hs_55_37-Human-homo_sapiens_core_55_37'"

for INFO in $INFOS
do
  DB=$(echo $INFO | perl -ne 'if ($_ =~ /(\w+\_\w+\_\w+)\-.*\-.*/){print "$1"}')
  export DB
  echo DB = $DB

  VER=$(echo $INFO | perl -ne 'if ($_ =~ /\w+\_(\w+)\_\w+\-.*\-.*/){print "$1"}')
  export VER
  echo VER = $VER

  SPECIES=$(echo $INFO | perl -ne 'if ($_ =~ /\w+\_\w+\_\w+\-(.*)\-.*/){$temp = $1; $temp =~ s/_/ /; print "$temp"}')
  export SPECIES
  echo SPECIES = $SPECIES

  ENSD=$(echo $INFO | perl -ne 'if ($_ =~ /\w+\_\w+\_\w+\-.*\-(.*)/){$temp = $1; chop($temp); print "$temp"}')
  export ENSD
  echo ENSD = $ENSD
  echo

  perl -ne '$db=$ENV{"DB"}; $ver=$ENV{"VER"}; $species=$ENV{"SPECIES"}; $ensd=$ENV{"ENSD"}; chomp ($_); @line =split("\t", $_); unless ($_ =~ /Chromosome/){print "/home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createIntergenicDatabase.pl  --ensembl_api_version=$ver  --species=\"$species\"  --ensembl_database=$ensd  --ensembl_server=ensembl01.bcgsc.ca  --ensembl_user=ensembl  --ensembl_password=ensembl  --alexa_database=ALEXA_$db  --alexa_server=jango.bcgsc.ca  --alexa_user=viewer  --alexa_password=viewer  --min_size=42  --chr_filter=\"$line[0]:$line[1]:$line[2]-$line[3]\"  --ucsc_align_dir=/projects/malachig/sequence_databases/$db/mrna_est/partitions/  --genbank_mapfile=/projects/malachig/sequence_databases/$db/mrna_est/GenBankToOrganism.btree  --wiggle=5  --outdir=/projects/malachig/sequence_databases/$db/intergenics/temp/  --logfile=/projects/malachig/sequence_databases/$db/logs/createIntergenicDatabase/createIntergenicDatabase_$line[0]_$line[1]_LOG.txt\n"}' /projects/malachig/sequence_databases/$DB/Regions_50_Genes.txt > /projects/malachig/sequence_databases/$DB/jobs/createIntergenicDatabase.sh

  rm -f /projects/malachig/sequence_databases/$DB/logs/createIntergenicDatabase/*.txt
  rm -f /projects/malachig/sequence_databases/$DB/intergenics/temp/*.fa
  rm -f /projects/malachig/sequence_databases/$DB/intergenics/temp/*Active.txt
  rm -f /projects/malachig/sequence_databases/$DB/intergenics/temp/*Silent.txt
  rm -f /projects/malachig/sequence_databases/$DB/intergenics/temp/*.txt
done

#Then submit these jobs to the cluster
ssh apollo
#DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
DBS="hs_55_37"
for DB in $DBS
do
  echo cd /projects/malachig/sequence_databases/$DB/jobs/
  cd /projects/malachig/sequence_databases/$DB/jobs/
  mqsub  --file createIntergenicDatabase.sh  --name $DB\_CIGD  --mkdir  --delay 5
  echo mqsub  --file createIntergenicDatabase.sh --name $DB\_CIGD  --mkdir  --delay 5
done

#Then check success rate
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo
  echo $DB
  grep -h "SCRIPT COMPLETE" /projects/malachig/sequence_databases/$DB/logs/createIntergenicDatabase/* | wc -l
  grep -v Chromosome /projects/malachig/sequence_databases/$DB/Regions_250_Genes.txt | wc -l
  grep -v Chromosome /projects/malachig/sequence_databases/$DB/Regions_50_Genes.txt | wc -l
done

#Retrieve jobs that need to be rerun - get list of jobs that completed according to their log files - and then filter the batch file with these
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/
  grep "SCRIPT COMPLETE" logs/createIntergenicDatabase/* | perl -ne 'if ($_ =~ /(create.*\.txt)/){print "$1\n"}' > logs/tmp.txt
  grep -v -f logs/tmp.txt jobs/createIntergenicDatabase.sh > jobs/createIntergenicDatabase_REPAIR.sh
  rm -f logs/tmp.txt
done
 
#Now join the annotation and fasta files together and create a blast database
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/intergenics/

  grep -h -v "Intergenic_ID" temp/*intergenics_annotated.txt > tmp.txt
  head -q -n 1 temp/*_annotated.txt | sort | uniq | cat - tmp.txt > intergenics_annotated.txt
  gzip intergenics_annotated.txt

  grep -h -v "Active_Region_ID" temp/*intergenicRegionsActive.txt > tmp.txt
  head -q -n 1 temp/*_intergenicRegionsActive.txt | sort | uniq | cat - tmp.txt > activeIntergenicRegions.txt
  gzip activeIntergenicRegions.txt

  grep -h -v "Silent_Region_ID" temp/*intergenicRegionsSilent.txt > tmp.txt
  head -q -n 1 temp/*_intergenicRegionsSilent.txt | sort | uniq | cat - tmp.txt > silentIntergenicRegions.txt
  gzip silentIntergenicRegions.txt

  cat temp/*.fa > blastdb/intergenics.fa
  cd blastdb/ 
  /home/pubseq/BioSw/BLAST2/blast2.2.18_x64/bin/formatdb -i intergenics.fa -t intergenics -p F -o F -n intergenics
  gzip intergenics.fa
done

#If the above step seems to have worked then clean-up temp files...



####################################################################################################
#12.) Create a database for transcript specific annotation records
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createTranscriptDatabase.pl  --database=ALEXA_$DB  --server=jango.bcgsc.ca  --user=viewer  --password=viewer  --annotation_dir=/projects/malachig/sequence_databases/$DB/  --outdir=/projects/malachig/sequence_databases/$DB/transcripts/
  gzip /projects/malachig/sequence_databases/$DB/transcripts/transcripts_annotated.txt
done


#Create a blast database for all full-length transcript sequences
DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createEnsemblTranscriptFasta.pl  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/createEnsemblTranscriptFasta.pl  --database=ALEXA_$DB  --server=jango.bcgsc.ca  --user=viewer  --password=viewer  --outfile=/projects/malachig/sequence_databases/$DB/transcripts/blastdb/transcripts.fa  --logfile=/projects/malachig/sequence_databases/$DB/logs/createEnsemblTranscriptsFasta_LOG.txt
  cd /projects/malachig/sequence_databases/$DB/transcripts/blastdb/
  /home/pubseq/BioSw/BLAST2/blast2.2.18_x64/bin/formatdb -i transcripts.fa -t transcripts -p F -o F -n transcripts
  gzip /projects/malachig/sequence_databases/$DB/transcripts/blastdb/transcripts.fa
done


####################################################################################################
#13.) For all feature types, append a unique FID (an id that is unique across all feature types)
#     *** All previous steps should be done first ! ***
# - Use a prefix for each feature type:
# G = genes
# T = transcripts
# ER = exon regions
# EJ = exon junctions
# EB = exon boundaries
# IN = introns
# AIN = active intron region
# SIN = silent intron region
# IG = intergenic region
# AIG = active intergenic region
# SIG = silent intergenic region

DBS="dm_54_54b gg_54_2l hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/$DB/
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=genes/genes_annotated.txt.gz  --outfile=genes/tmp.txt --prefix='G'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=transcripts/transcripts_annotated.txt.gz  --outfile=transcripts/tmp.txt --prefix='T'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=exonRegions/exonRegions_annotated.txt.gz  --outfile=exonRegions/tmp.txt --prefix='ER'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=exonJunctions/exonJunctions_62mers_annotated.txt.gz  --outfile=exonJunctions/tmp.txt --prefix='EJ'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=exonBoundaries/exonBoundaries_62mers_annotated.txt.gz  --outfile=exonBoundaries/tmp.txt --prefix='EB'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=introns/introns_annotated.txt.gz  --outfile=introns/tmp.txt --prefix='IN'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=introns/activeIntronRegions.txt.gz  --outfile=introns/tmp.txt --prefix='AIN'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=introns/silentIntronRegions.txt.gz  --outfile=introns/tmp.txt --prefix='SIN'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=intergenics/intergenics_annotated.txt.gz  --outfile=intergenics/tmp.txt --prefix='IG'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=intergenics/activeIntergenicRegions.txt.gz  --outfile=intergenics/tmp.txt --prefix='AIG'
  /home/malachig/svn/solexa_analysis/alternativeExpressionDatabase/appendFeatureId.pl  --infile=intergenics/silentIntergenicRegions.txt.gz  --outfile=intergenics/tmp.txt --prefix='SIG'
done


####################################################################################################
#14.) Create a backup of the ALEXA database
ssh jango
DBS="dm_54_54b gg_54_2l hs_53_36o hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  /home/malachig/svn/solexa_analysis/sql/backupAlexaDb.pl  --database=ALEXA_$DB  --server=jango.bcgsc.ca  --user=malachig  --password=gEEnom$  --mysql_dump_bin=/usr/bin/mysqldump  --working_dir=/projects/malachig/sequence_databases/$DB/alexa_db/  --logfile=/projects/malachig/sequence_databases/$DB/logs/backAlexaDb_LOG.txt
done


####################################################################################################
#15.) Create a summary statistics file for the build
#     - Summarize disk usage of the entire database package (compressed)
#     - Summarize the grand total number of features
#     - Summarize the number of each type of feature
#     - If applicable, summarize the number of features with EnsEMBL support, mRNA support, EST support, conservation support
DBS="dm_54_54b gg_54_2l hs_53_36o hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  echo starting $DB
  cd /projects/malachig/sequence_databases/$DB/exonJunctions/
  j_file="exonJunctions_62mers_annotated.txt.gz"
  j_file_known="known_junctions.txt"
  j_file_novel="novel_junctions.txt"
  ENSG_SUPPORT_COL=$(zcat $j_file | head -n 1 | perl -ne 'chomp($_); @line = split("\t", $_); foreach my $col (@line){$count++; if ($col eq "Supporting_EnsEMBL_Count"){print "$count";}}')
  export ENSG_SUPPORT_COL
  zcat $j_file | perl -ne '@line=split("\t", $_); if ($line[$ENV{"ENSG_SUPPORT_COL"}-1] > 0 || $line[$ENV{"ENSG_SUPPORT_COL"}-1] eq "Supporting_EnsEMBL_Count"){print "$_"}' > $j_file_known
  zcat $j_file | perl -ne '@line=split("\t", $_); if ($line[$ENV{"ENSG_SUPPORT_COL"}-1] == 0 || $line[$ENV{"ENSG_SUPPORT_COL"}-1] eq "Supporting_EnsEMBL_Count"){print "$_"}' > $j_file_novel
  gzip $j_file_known
  gzip $j_file_novel
  cd /projects/malachig/sequence_databases/$DB/exonBoundaries/
  b_file="exonBoundaries_62mers_annotated.txt.gz"
  b_file_known="known_boundaries.txt"
  b_file_novel="novel_boundaries.txt"
  ENSG_SUPPORT_COL=$(zcat $b_file | head -n 1 | perl -ne 'chomp($_); @line = split("\t", $_); foreach my $col (@line){$count++; if ($col eq "Supporting_EnsEMBL_Count"){print "$count";}}')
  export ENSG_SUPPORT_COL
  zcat $b_file | perl -ne '@line=split("\t", $_); if ($line[$ENV{"ENSG_SUPPORT_COL"}-1] > 0 || $line[$ENV{"ENSG_SUPPORT_COL"}-1] eq "Supporting_EnsEMBL_Count"){print "$_"}' > $b_file_known
  zcat $b_file | perl -ne '@line=split("\t", $_); if ($line[$ENV{"ENSG_SUPPORT_COL"}-1] == 0 || $line[$ENV{"ENSG_SUPPORT_COL"}-1] eq "Supporting_EnsEMBL_Count"){print "$_"}' > $b_file_novel
  gzip $b_file_known
  gzip $b_file_novel
  cd /projects/malachig/sequence_databases/$DB/
  OUTFILE="Stats_$DB.txt"
  rm -f $OUTFILE
  echo $OUTFILE
  FILES="
  genes/genes_annotated.txt.gz
  transcripts/transcripts_annotated.txt.gz
  exonRegions/exonRegions_annotated.txt.gz
  exonJunctions/exonJunctions_62mers_annotated.txt.gz
  exonJunctions/known_junctions.txt.gz
  exonJunctions/novel_junctions.txt.gz
  exonBoundaries/exonBoundaries_62mers_annotated.txt.gz
  exonBoundaries/known_boundaries.txt.gz
  exonBoundaries/novel_boundaries.txt.gz
  introns/introns_annotated.txt.gz
  introns/silentIntronRegions.txt.gz
  introns/activeIntronRegions.txt.gz
  intergenics/intergenics_annotated.txt.gz
  intergenics/silentIntergenicRegions.txt.gz
  intergenics/activeIntergenicRegions.txt.gz
  "
  echo "Feature_Type  Feature_Count EnsEMBL_Supported_Features  mRNA-EST_Supported_Features Conserved_Features  Base_Count  UnMasked_Base_Count Coding_Base_Count" >> $OUTFILE
  for f in $FILES
  do
    #Get the columns of interest
    ENSG_SUPPORT_COL=$(zcat $f | head -n 1 | perl -ne 'chomp($_); @line = split("\t", $_); foreach my $col (@line){$count++; if ($col eq "Supporting_EnsEMBL_Count"){print "$count";}}')
    MRNA_SUPPORT_COL=$(zcat $f | head -n 1 | perl -ne 'chomp($_); @line = split("\t", $_); foreach my $col (@line){$count++; if ($col eq "Supporting_mRNA_Count"){print "$count";}}')
    EST_SUPPORT_COL=$(zcat $f | head -n 1 | perl -ne 'chomp($_); @line = split("\t", $_); foreach my $col (@line){$count++; if ($col eq "Supporting_EST_Count"){print "$count";}}')
    CONSERVED_COL=$(zcat $f | head -n 1 | perl -ne 'chomp($_); @line = split("\t", $_); foreach my $col (@line){$count++; if ($col eq "Conserved_Species_Count"){print "$count";}}')
    BASE_COUNT_COL=$(zcat $f | head -n 1 | perl -ne 'chomp($_); @line = split("\t", $_); foreach my $col (@line){$count++; if ($col eq "Base_Count"){print "$count";}}')
    UNMASKED_BASE_COUNT_COL=$(zcat $f | head -n 1 | perl -ne 'chomp($_); @line = split("\t", $_); foreach my $col (@line){$count++; if ($col eq "UnMasked_Base_Count"){print "$count";}}')
    CODING_BASE_COUNT_COL=$(zcat $f | head -n 1 | perl -ne 'chomp($_); @line = split("\t", $_); foreach my $col (@line){$count++; if ($col eq "Coding_Base_Count"){print "$count";}}')
    #Get the total number of features
    TOTAL_FEATURES=$(zcat $f | grep -v Base_Count | wc -l)
    #Get the number of ensembl supported sequences ('NA' for feature types that do not have this column)
    ENSG_SUPPORT="NA"
    if [ -n "$ENSG_SUPPORT_COL" ]
      then
        ENSG_SUPPORT=$(zcat $f | cut -f $ENSG_SUPPORT_COL | perl -ne 'if ($_ =~ /(\d+)/){if ($1 > 0){$c++;}}; if (eof){if ($c > 0){print "$c"}else{print "0"}}')
    fi

    #Get the number of EST or mRNA supported sequences ('NA' for feature types that do not have these columns)
    SEQ_SUPPORT="NA"
    if [ -n "$MRNA_SUPPORT_COL" ]
      then
        SEQ_SUPPORT=$(zcat $f | cut -f $MRNA_SUPPORT_COL,$EST_SUPPORT_COL | perl -ne 'if ($_ =~ /(\d+)\s+(\d+)/){if ($1 > 0 | $2 > 0){$c++;}}; if (eof){if ($c > 0){print "$c"}else{print "0"}}')
    fi
    #Get the number of conserved sequence ('NA' for feature types that do not have this column)
    CONSERVED="NA"
    if [ -n "$CONSERVED_COL" ]
      then
        CONSERVED=$(zcat $f | cut -f $CONSERVED_COL | perl -ne 'if ($_ =~ /(\d+)/){if ($1 > 0){$c++;}}; if (eof){if ($c > 0){print "$c"}else{print "0"}}')
    fi
    #Get the grand base count
    BASE_COUNT="NA"
    if [ -n "$BASE_COUNT_COL" ]
      then
        BASE_COUNT=$(zcat $f | cut -f $BASE_COUNT_COL | perl -ne 'if ($_ =~ /(\d+)/){if ($1 >= 0){$c+=$1;}}; if (eof){if ($c > 0){print "$c"}else{print "0"}}')
    fi
    #Get the grand unmasked base count
    UNMASKED_BASE_COUNT="NA"
    if [ -n "$UNMASKED_BASE_COUNT_COL" ]
      then
        UNMASKED_BASE_COUNT=$(zcat $f | cut -f $UNMASKED_BASE_COUNT_COL | perl -ne 'if ($_ =~ /(\d+)/){if ($1 >= 0){$c+=$1;}}; if (eof){if ($c > 0){print "$c"}else{print "0"}}')
    fi
    #Get the grand protein coding base count
    CODING_BASE_COUNT="NA"
    if [ -n "$CODING_BASE_COUNT_COL" ]
      then
        CODING_BASE_COUNT=$(zcat $f | cut -f $CODING_BASE_COUNT_COL | perl -ne 'if ($_ =~ /(\d+)/){if ($1 >= 0){$c+=$1;}}; if (eof){if ($c > 0){print "$c"}else{print "0"}}')
    fi
    #print out the results
    echo "$f  $TOTAL_FEATURES $ENSG_SUPPORT $SEQ_SUPPORT  $CONSERVED  $BASE_COUNT $UNMASKED_BASE_COUNT  $CODING_BASE_COUNT" >> $OUTFILE
  done
  #Clean up the temp files
  rm -f exonJunctions/known_junctions.txt.gz
  rm -f exonJunctions/novel_junctions.txt.gz
  rm -f exonBoundaries/known_boundaries.txt.gz
  rm -f exonBoundaries/novel_boundaries.txt.gz

  perl -ne '$_ =~ s/\s+/\t/g; print "$_\n"' $OUTFILE > tmp.txt
  mv -f tmp.txt $OUTFILE
  echo completed $DB
  echo
done

####################################################################################################
#16.) Package and compress DB files
DBS="dm_54_54b gg_54_2l hs_53_36o hs_55_37 mm_54_37g pt_54_21k rn_54_34v sc_54_1i"
for DB in $DBS
do
  cd /projects/malachig/sequence_databases/
  echo
  echo Starting $DB
  tar -cf $DB.tar $DB/ChromosomeNames.txt $DB/Regions_250_Genes.txt $DB/Regions_50_Genes.txt $DB/Stats\_$DB.txt $DB/alexa_db $DB/exonBoundaries/ $DB/exonJunctions/ $DB/exonRegions/ $DB/genes/ $DB/intergenics/ $DB/introns/ $DB/transcripts/ $DB/repeats/
  gzip --best $DB.tar
  echo Done $DB
done

#Copy files over to public FTP server
cp /projects/malachig/sequence_databases/*.tar.gz /home/ftp/public/ALEXA/alexa_seq/









